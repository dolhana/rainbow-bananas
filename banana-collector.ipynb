{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# automatically reload python modules if there is a change\n",
    "# See https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# matplotlib plots are embedded inside of the notebook\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\DeclareMathOperator*{\\argmax}{arg\\,max}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Udacity Banana Collector\n",
    "\n",
    "This project demonstrates how to train an agent to collect bananas in a room using Deep Q-Networks algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "\n",
    "This project uses a Unity Banana Collector environment that is modified by Udacity.\n",
    "\n",
    "The following code cell loads the environment.\n",
    "\n",
    "You may need to install Mono on your Ubuntu machine if UnityEnvironment fails to load Mono library as shown below\n",
    "\n",
    "    Unable to load mono library from ./Banana_Linux/Banana_Data/MonoBleedingEdge/x86_64/libmonobdwgc-2.0.so\n",
    "    Failed to load mono\n",
    "    \n",
    "In that case, follow the instructions on https://www.mono-project.com/download/stable/#download-lin and install Mono. Below is the shell commands for Ubuntu 18.04\n",
    "\n",
    "    sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys 3FA7E0328081BFF6A14DA29AA6A19B38D3D831EF\n",
    "    echo \"deb https://download.mono-project.com/repo/ubuntu stable-bionic main\" | sudo tee /etc/apt/sources.list.d/mono-official-stable.list\n",
    "    sudo apt update\n",
    "    sudo apt install mono-devel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnityTimeOutException",
     "evalue": "The Unity environment took too long to respond. Make sure that :\n\t The environment does not need user interaction to launch\n\t The Academy and the External Brain(s) are attached to objects in the Scene\n\t The environment and the Python interface have compatible versions.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnityTimeOutException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a7724253416a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnityEnvironment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Banana_Linux/Banana.x86'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/banana/lib/python3.6/site-packages/unityagents/environment.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file_name, worker_id, base_port, curriculum, seed, docker_training, no_graphics)\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0maca_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_academy_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrl_init_parameters_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mUnityTimeOutException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/banana/lib/python3.6/site-packages/unityagents/environment.py\u001b[0m in \u001b[0;36msend_academy_parameters\u001b[0;34m(self, init_parameters)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnityInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrl_initialization_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrl_initialization_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrap_unity_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrl_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnityRLInput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnityOutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/banana/lib/python3.6/site-packages/unityagents/rpc_communicator.py\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munity_to_external\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             raise UnityTimeOutException(\n\u001b[0;32m---> 60\u001b[0;31m                 \u001b[0;34m\"The Unity environment took too long to respond. Make sure that :\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m                 \u001b[0;34m\"\\t The environment does not need user interaction to launch\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;34m\"\\t The Academy and the External Brain(s) are attached to objects in the Scene\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnityTimeOutException\u001b[0m: The Unity environment took too long to respond. Make sure that :\n\t The environment does not need user interaction to launch\n\t The Academy and the External Brain(s) are attached to objects in the Scene\n\t The environment and the Python interface have compatible versions."
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "env = UnityEnvironment(file_name='Banana_Linux/Banana.x86')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN\n",
    "\n",
    "Loss is defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "L_{DQN} = (R_{t+1} + \\gamma_{t+1} \\max_{a'}{q_{\\bar{\\theta}}}(S_{t+1},a') - q_\\theta(S_t,A_t))^2,\n",
    "\\end{equation}\n",
    "\n",
    "where\n",
    "  * $t$ : a time step randomly picked from the replay memory\n",
    "  * $\\theta$ : the parameters of the _online network_\n",
    "  * $\\bar{\\theta}$ : the parameters of the _target network_\n",
    "\n",
    "Notes:\n",
    "  * The gradient of the loss is back-propagated only into $\\theta$.\n",
    "  * $\\theta$ is periodically copied to $\\bar{\\theta}$.\n",
    "  * Mini-batches are sampled uniformly from the experience replay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double Q-learning\n",
    "\n",
    "Double Q-learning addresses the overestimation of DQN by decoupling, in the maximization performed for the bootstrap target, the selection of the action from its evaluation.\n",
    "\n",
    "Double Q-learning defines the loss as:\n",
    "\n",
    "$$\n",
    "L_{DDQN} = (R_{t+1} + \\gamma_{t+1} q_{\\bar{\\theta}}(S_{t+1},\\argmax_{a'}{q_\\theta (S_{t+q},a')}) - q_\\theta(S_t,A_t))^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prioritized replay\n",
    "\n",
    "Prioritized experence replay samples transitions with probability $p_t$ relative to the last encountered absolute _TD error_:\n",
    "\n",
    "$$\n",
    "p_t \\propto |R_{t+1} + \\gamma_{t+1} \\max_{a'} q_{\\bar{\\theta}}(S_{t+1},a') - q_\\theta(S_t,A_t)|^w,\n",
    "$$\n",
    "\n",
    "where $w$ is a hyper-parameter that determines the shape of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dueling networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-step learning\n",
    "\n",
    "A multi-step variant of DQN uses foward-view _multi-step_ targets and the alternative loss, which is defined as:\n",
    "\n",
    "$$\n",
    "L_{multi-step} = (R_t^{(n)} + \\gamma_t^{(n)} \\max_{a'} q_{\\bar{\\theta}}(S_{t+n},a') - q_\\theta(S_t,A_t))^2,\n",
    "$$\n",
    "where\n",
    "$$\n",
    "R_t^{(n)} \\equiv \\sum_{k=0}^{n-1} \\gamma_t^{(k)} R_{t+k+1}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import agent"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
